{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arabic-font-classification-final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AQJUJ3DPsPfP",
        "RBVC866usGeU",
        "fB2Y203CssdO",
        "aff5mVAEszF4",
        "cvxob5nEs2Lb",
        "X4I3syHss4kr"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km6tttbmrhYd",
        "colab_type": "text"
      },
      "source": [
        "# Arabic Font Classification\n",
        "Author: Mahmoud Aslan\n",
        "\n",
        "Date: 18-7-2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQJUJ3DPsPfP",
        "colab_type": "text"
      },
      "source": [
        "## Ensure Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heYOP546r0ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__ == '2.2.0'"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4hD9mgJM_zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02b9a057-ad96-4e3a-9a4d-e4e0a8aa34d9"
      },
      "source": [
        "!pip install tensorflow-determinism"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-determinism in /usr/local/lib/python3.6/dist-packages (0.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci2DKA6wNJnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random as rn\n",
        "import os\n",
        "\n",
        "rn.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "rng = tf.random.experimental.Generator.from_seed(1234)\n",
        "\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['PYTHONHASHSEED']=str(0)\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = ''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBVC866usGeU",
        "colab_type": "text"
      },
      "source": [
        "## Fetch and load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-CGmXEYMkrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "06b0a25e-b5b5-43a2-d23c-c12e3902165f"
      },
      "source": [
        "!wget 'https://github.com/mhmoodlan/arabic-font-classification/releases/download/v0.1.0/rufa.tar.gz' && tar -xzf '/content/rufa.tar.gz'"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-17 21:20:45--  https://github.com/mhmoodlan/arabic-font-classification/releases/download/v0.1.0/rufa.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/280475345/18288f80-c87d-11ea-95ed-712fd4c4a137?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200717%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200717T212045Z&X-Amz-Expires=300&X-Amz-Signature=3b22dd538205d2710e7e4140fd5e0c6dcb0fe3ab3ac727d5e28bb8d67bdac63c&X-Amz-SignedHeaders=host&actor_id=0&repo_id=280475345&response-content-disposition=attachment%3B%20filename%3Drufa.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-17 21:20:45--  https://github-production-release-asset-2e65be.s3.amazonaws.com/280475345/18288f80-c87d-11ea-95ed-712fd4c4a137?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200717%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200717T212045Z&X-Amz-Expires=300&X-Amz-Signature=3b22dd538205d2710e7e4140fd5e0c6dcb0fe3ab3ac727d5e28bb8d67bdac63c&X-Amz-SignedHeaders=host&actor_id=0&repo_id=280475345&response-content-disposition=attachment%3B%20filename%3Drufa.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.26.252\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.26.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121264953 (116M) [application/octet-stream]\n",
            "Saving to: ‘rufa.tar.gz’\n",
            "\n",
            "rufa.tar.gz         100%[===================>] 115.65M  53.9MB/s    in 2.1s    \n",
            "\n",
            "2020-07-17 21:20:48 (53.9 MB/s) - ‘rufa.tar.gz’ saved [121264953/121264953]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBCcAI_PPVo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3806a3f2-f68d-4b7b-9aa2-51f83bead324"
      },
      "source": [
        "print('# of real Ruqaa images: ', len(os.listdir('/content/rufa/real/ruqaa/')))\n",
        "print('# of real Farsi images: ', len(os.listdir('/content/rufa/real/farsi/')))\n",
        "print('# synthesized Ruqaa: ', len(os.listdir('/content/rufa/synth/ruqaa/')))\n",
        "print('# synthesized Farsi: ', len(os.listdir('/content/rufa/synth/farsi/')))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of real Ruqaa images:  260\n",
            "# of real Farsi images:  256\n",
            "# synthesized Ruqaa:  20000\n",
            "# synthesized Farsi:  20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVi7ghEmO5St",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cca1f598-d804-481e-d916-80240c2b91ff"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "synth_dir = Path('/content/rufa/synth')\n",
        "real_dir = Path('/content/rufa/real')\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in real_dir.glob('*')])\n",
        "CLASS_NAMES"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ruqaa', 'farsi'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXFInzYpQFrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "synth_paths = tf.data.Dataset.list_files(str(synth_dir / '*/*.jpg'), seed=42)\n",
        "real_paths = tf.data.Dataset.list_files(str(real_dir / '*/*.jpg'), seed=42)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB2Y203CssdO",
        "colab_type": "text"
      },
      "source": [
        "## Train, val, mismatch, test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkqcGEzQ-Zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_max_data_size = 2**np.int('32')\n",
        "_test_ratio = '0.2'\n",
        "\n",
        "\n",
        "def test_set_check(item):\n",
        "    id = tf.strings.split(tf.strings.split(item, os.sep)[-1], '.')[0]\n",
        "    hash = tf.strings.to_hash_bucket_fast(id, _max_data_size)\n",
        "    return tf.cast(hash, tf.float64) < float(_test_ratio) * _max_data_size\n",
        "\n",
        "def train_set_check(item):\n",
        "    id = tf.strings.split(tf.strings.split(item, os.sep)[-1], '.')[0]\n",
        "    hash = tf.strings.to_hash_bucket_fast(id, _max_data_size)\n",
        "    return tf.cast(hash, tf.float64) >= float(_test_ratio) * _max_data_size"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyE8Bls6RIQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_paths = synth_paths.filter(train_set_check)\n",
        "val_paths = synth_paths.filter(test_set_check)\n",
        "mismatch_paths = real_paths.filter(test_set_check)\n",
        "test_paths = real_paths.filter(train_set_check)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aff5mVAEszF4",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRFjxM56RXaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "mapping = {0: 'farsi', 1: 'ruqaa'}\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size, seed=42)\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds\n",
        "\n",
        "def parse_image(data_instance):\n",
        "  parts = tf.strings.split(data_instance, os.sep)\n",
        "  label = tf.cast(tf.argmax(tf.cast(parts[-2] == np.array(list(mapping.values())), dtype=tf.float16)), tf.float16)\n",
        "\n",
        "  image = tf.io.read_file(data_instance)\n",
        "  image = tf.image.decode_jpeg(image, 1)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "  if parts[-3] == 'synth':\n",
        "    noise = rng.normal(shape=tf.shape(image), mean=0.0, stddev=0.015, dtype=tf.float32)\n",
        "    image = tf.add( image, noise)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "\n",
        "    image = tf.image.adjust_jpeg_quality(image, 90)\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmIrVEVKSO3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = train_paths.map(parse_image)\n",
        "val_ds = val_paths.map(parse_image)\n",
        "mismatch_ds = mismatch_paths.map(parse_image)\n",
        "full_train_ds = train_ds.concatenate(val_ds.concatenate(mismatch_ds))\n",
        "test_ds = test_paths.map(parse_image)\n",
        "\n",
        "train_ds = prepare_for_training(train_ds)\n",
        "val_ds = prepare_for_training(val_ds)\n",
        "mismatch_ds = prepare_for_training(mismatch_ds)\n",
        "full_train_ds = prepare_for_training(full_train_ds)\n",
        "test_ds = prepare_for_training(test_ds)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvxob5nEs2Lb",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ7Sbl-SSRUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn(input_shape, output_shape):\n",
        "    num_classes = output_shape[0]\n",
        "    dropout_seed = 708090\n",
        "    kernel_seed = 42\n",
        "  \n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=input_shape, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Dropout(0.1, seed=dropout_seed),\n",
        "      tf.keras.layers.Conv2D(32, 5, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Dropout(0.1, seed=dropout_seed),\n",
        "      tf.keras.layers.Conv2D(64, 10, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Dropout(0.1, seed=dropout_seed),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu', kernel_regularizer='l2', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.Dropout(0.2, seed=dropout_seed),\n",
        "      tf.keras.layers.Dense(16, activation='relu', kernel_regularizer='l2', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.Dropout(0.2, seed=dropout_seed),\n",
        "      tf.keras.layers.Dense(num_classes, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed))\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vItUjk8iSy6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODE = 'val'\n",
        "epochs = 6\n",
        "callbacks = None"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAICHuZ3Sj5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "83e4f1ac-f462-4494-8c51-46ead39b84cc"
      },
      "source": [
        "model = cnn((100, 100, 1), (1,))\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer='Adam', metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 98, 98, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 45, 45, 32)        12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 13, 13, 64)        204864    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 514,977\n",
            "Trainable params: 514,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4I3syHss4kr",
        "colab_type": "text"
      },
      "source": [
        "## Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uup72W8uS5G8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "9e2047aa-dd22-4607-d866-ab706114b0ce"
      },
      "source": [
        "if MODE == 'val':\n",
        "  model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds\n",
        "  )\n",
        "elif MODE == 'test':\n",
        "  model.fit(\n",
        "    full_train_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks\n",
        "  )"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1004/1004 [==============================] - 124s 123ms/step - loss: 0.3770 - accuracy: 0.8473 - val_loss: 0.0675 - val_accuracy: 0.9943\n",
            "Epoch 2/6\n",
            "1004/1004 [==============================] - 37s 37ms/step - loss: 0.0594 - accuracy: 0.9921 - val_loss: 0.0397 - val_accuracy: 0.9963\n",
            "Epoch 3/6\n",
            "1004/1004 [==============================] - 38s 38ms/step - loss: 0.0427 - accuracy: 0.9948 - val_loss: 0.0238 - val_accuracy: 0.9992\n",
            "Epoch 4/6\n",
            "1004/1004 [==============================] - 37s 37ms/step - loss: 0.0345 - accuracy: 0.9961 - val_loss: 0.0168 - val_accuracy: 0.9982\n",
            "Epoch 5/6\n",
            "1004/1004 [==============================] - 36s 36ms/step - loss: 0.0273 - accuracy: 0.9971 - val_loss: 0.0150 - val_accuracy: 0.9997\n",
            "Epoch 6/6\n",
            "1004/1004 [==============================] - 37s 37ms/step - loss: 0.0272 - accuracy: 0.9975 - val_loss: 0.0434 - val_accuracy: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIRrUgizTOd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "feeb1b40-c2e4-4915-9a13-3744c8332055"
      },
      "source": [
        "if MODE == 'val':\n",
        "  mismatch_score = model.evaluate(mismatch_ds)\n",
        "  print(f\"Data mismatch score: {mismatch_score}\")\n",
        "elif MODE == 'test':\n",
        "  test_score = model.evaluate(test_ds)\n",
        "  print(f\"Test score: {test_score}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.9293\n",
            "Data mismatch score: [0.24949957430362701, 0.9292929172515869]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WxxzMFuTtDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if MODE == 'val':\n",
        "  assert np.allclose(mismatch_score, [.249499, .929292])\n",
        "elif MODE == 'test':\n",
        "  assert np.allclose(test_score, [.231625, .971222])"
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}